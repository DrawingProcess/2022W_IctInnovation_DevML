{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "205c5346-2cf3-4222-82c4-e9d00624c845",
   "metadata": {},
   "source": [
    "# 역전파\n",
    "\n",
    "역전파를 수행하면 최종적으로 나온 오류를 다시 뒤로 전달해야 한다. 그 과정을 코드로 나타내보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ae1216c-106d-41da-bc75-e1decdc42573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_y: 0.512372477962617\n",
      "error: 0.487627522037383\n",
      "output_error_term: 0.1218322353606694\n",
      "hidden_error_term: 0.003045501323732555\n",
      "del_w_output: 0.030153488404045865\n",
      "del_w_hidden: [0.00015228 0.00045683]\n",
      "l2_weights: 0.06984651159595415\n",
      "l1_weights: [ 0.39984772 -0.20045683]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# 시그모이드\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "\n",
    "# 시그모이드 기울기\n",
    "def sigmoid_prime(x): \n",
    "    return sigmoid(x) * (1-sigmoid(x))\n",
    "\n",
    "\n",
    "# 입력값과 레이블, 변수를 정의한다.\n",
    "input1 = np.array([0.1, 0.3])\n",
    "weights = np.array([0.4, -0.2])\n",
    "hidden_weight = 0.1\n",
    "true_y = 1\n",
    "\n",
    "# 포워드 패스\n",
    "l1 = sigmoid(np.dot(input1, weights))\n",
    "l2 = sigmoid(np.dot(l1, hidden_weight))\n",
    "pred_y = l2\n",
    "\n",
    "# 오차와 에러텀 계산\n",
    "error = abs(true_y - l2)\n",
    "output_error_term = error * sigmoid_prime(np.dot(l1, hidden_weight))\n",
    "hidden_error_term = output_error_term * hidden_weight * sigmoid_prime(np.dot(input1, weights))\n",
    "\n",
    "# 업데이트할 w를 계산\n",
    "learning_rate = 0.5\n",
    "del_w_output = learning_rate * output_error_term * l1 # 출력층에서는 l1의 결과가 입력값이 된다.\n",
    "del_w_hidden = learning_rate * hidden_error_term * input1\n",
    "\n",
    "# 업데이트 수행\n",
    "hidden_weight -= del_w_output\n",
    "weights -= del_w_hidden\n",
    "\n",
    "print(f'''\\\n",
    "pred_y: {l2}\n",
    "error: {error}\n",
    "output_error_term: {output_error_term}\n",
    "hidden_error_term: {hidden_error_term}\n",
    "del_w_output: {del_w_output}\n",
    "del_w_hidden: {del_w_hidden}\n",
    "l2_weights: {hidden_weight}\n",
    "l1_weights: {weights}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9291d203-b11c-41c5-b688-bd983726f30c",
   "metadata": {},
   "source": [
    "# 넘파이를 활용한 딥러닝 네트워크 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8194197d-7cee-4754-854e-28f876cd5c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Training set error: 11.395 Traing set accuracy: 0.798 Test set error: 10.021 Test set accuracy: 0.758 \n",
      "Epoch: 1 Training set error: 35.897 Traing set accuracy: 0.853 Test set error: 31.514 Test set accuracy: 0.822 \n",
      "Epoch: 2 Training set error: 55.185 Traing set accuracy: 0.874 Test set error: 48.524 Test set accuracy: 0.852 \n",
      "Epoch: 3 Training set error: 69.441 Traing set accuracy: 0.886 Test set error: 61.179 Test set accuracy: 0.865 \n",
      "Epoch: 4 Training set error: 80.297 Traing set accuracy: 0.893 Test set error: 70.881 Test set accuracy: 0.869 \n",
      "Epoch: 5 Training set error: 88.852 Traing set accuracy: 0.899 Test set error: 78.570 Test set accuracy: 0.877 \n",
      "Epoch: 6 Training set error: 95.812 Traing set accuracy: 0.903 Test set error: 84.852 Test set accuracy: 0.882 \n",
      "Epoch: 7 Training set error: 101.633 Traing set accuracy: 0.906 Test set error: 90.124 Test set accuracy: 0.881 \n",
      "Epoch: 8 Training set error: 106.615 Traing set accuracy: 0.911 Test set error: 94.647 Test set accuracy: 0.883 \n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, t_train), (x_test, t_test) = mnist.load_data()\n",
    "\n",
    "# 성능 이슈로 시그모이드가 아닌 relu 함수를 사용한다.\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "\n",
    "# 렐루의 미분 함수\n",
    "def relu2deriv(output): \n",
    "    return output >= 0 \n",
    "\n",
    "\n",
    "# 소프트맥스 함수\n",
    "def softmax(a):\n",
    "    # x를 그대로 전달하는 것이 아니라 각 값에서 최대 값을 차감\n",
    "    x = a - np.max(a) #의 값은 기존보다 훨씬 작은 값이 안정화됨\n",
    "    f_y = np.exp(x) / np.sum(np.exp(x)) # 오리지날 softmax 함수\n",
    "    return f_y\n",
    "\n",
    "\n",
    "# mnist 데이터셋의 전치리 수행\n",
    "training_sample, test_sample = 10000, 1000\n",
    "training_images = (x_train[0:training_sample]/255).reshape(-1, 784)\n",
    "test_images = (x_test[0:test_sample]/255).reshape(-1, 784)\n",
    "\n",
    "# y 레이블에 대한 원핫인코딩 수행\n",
    "number_list = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "ohe_y = OneHotEncoder(categories=[number_list], handle_unknown='ignore')\n",
    "ohe_y.fit(t_train.reshape(-1,1))\n",
    "training_labels  = ohe_y.transform(t_train.reshape(-1,1)).toarray()[:training_sample]\n",
    "test_labels = ohe_y.transform(t_test.reshape(-1,1)).toarray()[:test_sample]\n",
    "\n",
    "# 랜덤 시드\n",
    "seed = 884736743\n",
    "rng = np.random.default_rng(seed)\n",
    "\n",
    "# 레이어에 필요한 변수 설정\n",
    "learning_rate= 0.0005\n",
    "epochs = 20\n",
    "hidden_size= 100       # 히든 계층의 노드 개수\n",
    "pixels_per_image = 784 # 입력 계층의 노드 개수\n",
    "num_labels = 10\n",
    "\n",
    "# 각 레이어에 필요한 가중치 설정\n",
    "weights_1 = 0.2 * rng.random((pixels_per_image, hidden_size)) - 0.1 # 784x100\n",
    "weights_2 = 0.2 * rng.random((hidden_size, num_labels)) - 0.1       # 100x10\n",
    "\n",
    "# 학습 진행 현황을 기록할 저장소\n",
    "store_training_loss = []\n",
    "store_training_accurate_pred = []\n",
    "store_test_loss = []\n",
    "store_test_accurate_pred = []\n",
    "\n",
    "# 루프 시작\n",
    "for j in range(epochs):\n",
    "    training_loss = 0.0\n",
    "    training_accurate_predictions = 0\n",
    "    \n",
    "    for i in range(len(training_images)):\n",
    "        # 포워드 패스\n",
    "        layer_0 = training_images[i] # input\n",
    "        layer_1 = relu(np.dot(layer_0, weights_1)) # l1\n",
    "        layer_2 = softmax(np.dot(layer_1, weights_2)) # l2\n",
    "        \n",
    "        # SSE 계산\n",
    "        training_loss += np.sum((training_lables[i] - layer_2) ** 2)\n",
    "        \n",
    "        # 정확률 계산\n",
    "        training_accurate_predictions += int(np.argmax(layer_2) == np.argmax(training_labels[i])) # 정답 개수를 추가\n",
    "        \n",
    "        # 업데이트를 위해 오차 계산\n",
    "        layer_2_delta = training_labels[i] - layer_2 # 마지막 레이어의 Loss\n",
    "        layer_1_delta = np.dot(weights_2, layer_2_delta) * relu2deriv(layer_1) # 한 레이어 전의 오류 계산\n",
    "        \n",
    "        # 변화할 가중치를 원래 가중치에 더함\n",
    "        weights_1 += learning_rate * np.outer(layer_0, layer_1_delta)\n",
    "        weights_2 += learning_rate * np.outer(layer_1, layer_2_delta)\n",
    "        \n",
    "    # 한번의 에포치가 종료될 때마다 훈련 결과를 측정한다.\n",
    "    results = relu(test_images @ weights_1) @ weights_2\n",
    "    test_loss = np.sum((test_labels - results) ** 2 ) # MSE\n",
    "    test_accurate_predictions = np.sum(np.argmax(results, axis=1) == np.argmax(test_labels, axis=1))\n",
    "    \n",
    "    results = relu(training_images @ weights_1) @ weights_2\n",
    "    training_loss = np.sum((training_labels - results) ** 2 ) # MSE\n",
    "    training_accurate_predictions = np.sum(np.argmax(results, axis=1) == np.argmax(training_labels, axis=1))\n",
    "    \n",
    "    # 이번 에포치의 결과를 저장한다.\n",
    "    store_training_loss.append(training_loss)\n",
    "    store_training_accurate_pred.append(training_accurate_predictions)\n",
    "    store_test_loss.append(test_loss)\n",
    "    store_test_accurate_pred.append(test_accurate_predictions)\n",
    "    \n",
    "    # 이벤 에포치의 결과를 프린트\n",
    "    print(f'''\\\n",
    "Epoch: {j} Training set error: {training_loss / float(len(training_images)):.3f} \\\n",
    "Traing set accuracy: {training_accurate_predictions / float(len(training_images)):.3f} \\\n",
    "Test set error: {test_loss / float(len(test_images)):.3f} \\\n",
    "Test set accuracy: {test_accurate_predictions / float(len(test_images)):.3f} \\\n",
    "''')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25d86af-9b59-4500-8cfa-2e03aa671487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "loss_history = pd.DataFrame([store_training_loss, store_test_loss], \n",
    "                            index = ['train_loss', 'test_loss'])\n",
    "acc_history = pd.DataFrame([store_training_accurate_pred, store_test_accurate_pred], \n",
    "                            index = ['train_acc', 'test_acc'])\n",
    "\n",
    "loss_history.T.plot()\n",
    "plt.show()\n",
    "acc_history.T.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82585ac-93ea-44a1-901b-5ab44ed40f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
