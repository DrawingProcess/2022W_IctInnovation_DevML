{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torchvision.datasets as dsets\nimport torchvision.transforms as transforms\nimport torch.nn.init\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n# 랜덤 시드 고정\ntorch.manual_seed(0)\n\n# GPU 사용 가능일 경우 랜덤 시드 고정\nif device == 'cuda':\n    torch.cuda.manual_seed_all(0)\n\n# 데이터셋 가져오기\nmnist_train = dsets.STL10(root='STL10_data/',\n                          split=\"train\", \n                          transform=transforms.ToTensor(), \n                          download=True)\n\nmnist_test = dsets.STL10(root='STL10_data/',\n                         split=\"test\",\n                         transform=transforms.ToTensor(),\n                         download=True)\n\n# 하이퍼 파라미터 설정\nlearning_rate = 0.001\ntraining_epochs = 40\nbatch_size = 64\n\n# 데이터 로더 정의\ndata_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n                                          batch_size=batch_size,\n                                          shuffle=True,\n                                          drop_last=True)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-17T12:10:32.500559Z","iopub.execute_input":"2022-11-17T12:10:32.500949Z","iopub.status.idle":"2022-11-17T12:10:44.886202Z","shell.execute_reply.started":"2022-11-17T12:10:32.500917Z","shell.execute_reply":"2022-11-17T12:10:44.885118Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# CNN 모델 정의\nclass CNN(torch.nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        # 첫번째층\n        # ImgIn shape=(?, 96, 96, 3)\n        #    Conv     -> (?, 96, 96, 32)\n        #    Pool     -> (?, 48, 48, 32)\n        self.layer1 = torch.nn.Sequential(\n            torch.nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n            torch.nn.ReLU(),\n            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n\n        # 두번째층\n        # ImgIn shape=(?, 48, 48, 32)\n        #    Conv      ->(?, 48, 48, 64)\n        #    Pool      ->(?, 24, 24, 64)\n        self.layer2 = torch.nn.Sequential(\n            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n            torch.nn.ReLU(),\n            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n        \n        # 세번째층\n        # ImgIn shape=(?, 24, 24, 64)\n        #    Conv      ->(?, 24, 24, 128)\n        #    Pool      ->(?, 12, 12, 128)\n        self.layer3 = torch.nn.Sequential(\n            torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n            torch.nn.ReLU(),\n            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n\n        # 전결합층 7x7x64 inputs -> 10 outputs\n        self.fc = torch.nn.Linear(12 * 12 * 128, 10, bias=True)\n\n        # 전결합층 한정으로 가중치 초기화\n        torch.nn.init.xavier_uniform_(self.fc.weight)\n\n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = out.view(out.size(0), -1)   # 전결합층을 위해서 Flatten\n        out = self.fc(out)\n        return out\n\n    \n# CNN 모델 생성\nmodel = CNN().to(device)\n\n# 로스와 최적화 함수 설정\ncriterion = torch.nn.CrossEntropyLoss().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n\n# 데이터 로드\ntotal_batch = len(data_loader)\nprint('총 배치의 수 : {}'.format(total_batch))\n\n# 트레이닝 데이터셋으로 epoch 실행\nfor epoch in range(training_epochs):\n    avg_cost = 0\n\n    for X, Y in data_loader: # 미니 배치 단위로 꺼내온다. X는 미니 배치, Y는 레이블.\n        X = X.to(device)\n        Y = Y.to(device)\n\n        optimizer.zero_grad()\n        hypothesis = model(X)\n        cost = criterion(hypothesis, Y)\n        cost.backward()\n        optimizer.step()\n\n        avg_cost += cost / total_batch\n        \n\n    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))\n\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-11-17T13:00:13.765541Z","iopub.execute_input":"2022-11-17T13:00:13.765931Z","iopub.status.idle":"2022-11-17T13:03:07.394082Z","shell.execute_reply.started":"2022-11-17T13:00:13.765899Z","shell.execute_reply":"2022-11-17T13:03:07.393031Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"총 배치의 수 : 250\n[Epoch:    1] cost = 1.69908333\n[Epoch:    2] cost = 1.31318772\n[Epoch:    3] cost = 1.10171819\n[Epoch:    4] cost = 0.928379953\n[Epoch:    5] cost = 0.755661845\n[Epoch:    6] cost = 0.622439027\n[Epoch:    7] cost = 0.510874271\n[Epoch:    8] cost = 0.417368472\n[Epoch:    9] cost = 0.355483621\n[Epoch:   10] cost = 0.287039012\n[Epoch:   11] cost = 0.219571874\n[Epoch:   12] cost = 0.175276682\n[Epoch:   13] cost = 0.147072569\n[Epoch:   14] cost = 0.128132552\n[Epoch:   15] cost = 0.105479017\n[Epoch:   16] cost = 0.0933204293\n[Epoch:   17] cost = 0.0793307349\n[Epoch:   18] cost = 0.073362723\n[Epoch:   19] cost = 0.0602688193\n[Epoch:   20] cost = 0.0576844886\n[Epoch:   21] cost = 0.0494777597\n[Epoch:   22] cost = 0.0371099487\n[Epoch:   23] cost = 0.034028098\n[Epoch:   24] cost = 0.033948455\n[Epoch:   25] cost = 0.0482948795\n[Epoch:   26] cost = 0.0472458899\n[Epoch:   27] cost = 0.0420369096\n[Epoch:   28] cost = 0.0440836884\n[Epoch:   29] cost = 0.0311597958\n[Epoch:   30] cost = 0.0301720221\n[Epoch:   31] cost = 0.0324718207\n[Epoch:   32] cost = 0.0300669279\n[Epoch:   33] cost = 0.0489408001\n[Epoch:   34] cost = 0.0351983309\n[Epoch:   35] cost = 0.0308662988\n[Epoch:   36] cost = 0.035633523\n[Epoch:   37] cost = 0.0342551544\n[Epoch:   38] cost = 0.029120665\n[Epoch:   39] cost = 0.0170125589\n[Epoch:   40] cost = 0.013787264\n","output_type":"stream"}]},{"cell_type":"code","source":"data_loader = torch.utils.data.DataLoader(dataset=mnist_test, batch_size=32)\n\nimport numpy as np\n\naccuracy_list = []\nwith torch.no_grad():\n    accuracy = 0\n    for X, Y in data_loader: # 미니 배치 단위로 꺼내온다. X는 미니 배치, Y는 레이블.\n        X_test = X.to(device)\n        Y_test = Y.to(device)\n        # 학습을 진행하지 않을 것이므로 torch.no_grad()\n\n        prediction = model(X_test)\n        accuracy += (torch.argmax(prediction, 1) == Y_test).float().mean()\n    accuracy /= len(data_loader)\n    print('Accuracy:', accuracy)","metadata":{"execution":{"iopub.status.busy":"2022-11-17T13:03:07.396651Z","iopub.execute_input":"2022-11-17T13:03:07.397770Z","iopub.status.idle":"2022-11-17T13:03:11.527662Z","shell.execute_reply.started":"2022-11-17T13:03:07.397726Z","shell.execute_reply":"2022-11-17T13:03:11.526503Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"Accuracy: tensor(0.9888, device='cuda:0')\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}