{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# pytorch GPU 튜토리얼\n## GPU가 사용 가능한지 확인","metadata":{}},{"cell_type":"code","source":"import torch\n\ntorch.cuda.is_available() # 기본 CPU이기 때문에 실패","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-16T15:20:38.601279Z","iopub.execute_input":"2022-11-16T15:20:38.601679Z","iopub.status.idle":"2022-11-16T15:20:42.254807Z","shell.execute_reply.started":"2022-11-16T15:20:38.601645Z","shell.execute_reply":"2022-11-16T15:20:42.253800Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\n# ... 메뉴로 이동해서 Accelerator - GPU T4 x2로 변경한다.\ntorch.cuda.is_available() ","metadata":{"execution":{"iopub.status.busy":"2022-11-16T15:20:42.256995Z","iopub.execute_input":"2022-11-16T15:20:42.257811Z","iopub.status.idle":"2022-11-16T15:20:42.264497Z","shell.execute_reply.started":"2022-11-16T15:20:42.257774Z","shell.execute_reply":"2022-11-16T15:20:42.263336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"기본적으로 생성된 변수는 모두 CPU에 존재한다.","metadata":{}},{"cell_type":"code","source":"list0 = [1,2,3,4]\nx = torch.tensor(list0)\nx.is_cuda","metadata":{"execution":{"iopub.status.busy":"2022-11-16T15:20:42.265538Z","iopub.execute_input":"2022-11-16T15:20:42.265788Z","iopub.status.idle":"2022-11-16T15:20:42.276775Z","shell.execute_reply.started":"2022-11-16T15:20:42.265764Z","shell.execute_reply":"2022-11-16T15:20:42.275580Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = x.to('cuda')\nx.is_cuda","metadata":{"execution":{"iopub.status.busy":"2022-11-16T15:20:42.373203Z","iopub.execute_input":"2022-11-16T15:20:42.375076Z","iopub.status.idle":"2022-11-16T15:20:47.190581Z","shell.execute_reply.started":"2022-11-16T15:20:42.375049Z","shell.execute_reply":"2022-11-16T15:20:47.189506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"다음 코드를 cuda로 실행할 수 있도록 수정해보자.","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport numpy as np\nimport os \n\n# 트레이닝 데이터셋을 다운로드한다.\ntraining_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=True,\n    download=True,\n    transform=ToTensor()\n)\n\n# 테스트 데이터셋을 다운로드한다.\ntest_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=False,\n    download=True,\n    transform=ToTensor()\n)\n\ntrain_dataloader = DataLoader(training_data, batch_size=64)\ntest_dataloader = DataLoader(test_data, batch_size=64)\n\nclass DNN(nn.Module):\n    def __init__(self):\n        super(DNN, self).__init__()\n        self.linear_relu_stack = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(784, 512),\n            nn.ReLU(),\n            nn.Linear(512, 512),\n            nn.ReLU(),\n            nn.Linear(512, 10),\n        )\n        \n    # 포워드 패스    \n    def forward(self, x):\n        return self.linear_relu_stack(x)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-11-16T15:20:47.192797Z","iopub.execute_input":"2022-11-16T15:20:47.193174Z","iopub.status.idle":"2022-11-16T15:20:53.442729Z","shell.execute_reply.started":"2022-11-16T15:20:47.193138Z","shell.execute_reply":"2022-11-16T15:20:53.441537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n\n\ndef train_loop(dataloader, model, loss_fn, optimzer, device):\n    size = len(dataloader.dataset)\n    model.train() # 모델을 훈련 모드로 설정\n    \n    for batch, (X, y) in enumerate(dataloader):\n        X = X.to(device)\n        y = y.to(device)\n        pred = model(X) # 포워드 패스 수행\n        loss = loss_fn(pred, y) # CE 연산\n        \n        optimzer.zero_grad() # 0 으로 초기화\n        loss.backward() # 역전파하여 그래디언트 계산\n        optimzer.step() # 연산된 그래디언트를 사용해 파라미터를 업데이트\n        \n        if batch % 100 == 0: # 매 100회차 마다 다음 내용 출력\n            loss, current = loss.item(), batch * len(X)\n            #print(f'loss: {loss}, [{current:>5d}/{size:>5d}]')\n\ndef test_loop(dataloader, model, loss_fn, device):\n    size = len(dataloader.dataset)\n    num_batches = len(dataloader)\n    test_loss, correct = 0, 0\n    model.eval() # 모델을 실행 모드로 설정\n    \n    with torch.no_grad(): # 그래디언트 연산 안함\n        for X, y in dataloader:\n            X = X.to(device)\n            y = y.to(device)\n            \n            pred = model(X) # 포워드 패스 수행\n            test_loss += loss_fn(pred, y) # CE 연산\n            correct += (pred.argmax(1) == y).type(torch.float).sum().item() # 결과 일치하는지 확인\n    \n    test_loss /= num_batches\n    correct /= size\n    print(f'Test Error: \\n 정확도: {(100*correct):>0.1f}% 평균 Loss: {test_loss:>8f}\\n')\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-11-16T15:21:45.980333Z","iopub.execute_input":"2022-11-16T15:21:45.980731Z","iopub.status.idle":"2022-11-16T15:21:45.993119Z","shell.execute_reply.started":"2022-11-16T15:21:45.980698Z","shell.execute_reply":"2022-11-16T15:21:45.992068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run(device):\n    #device = 'cuda:0' if torch.cuda.is_available() else 'cpu'   \n    #device = 'cpu'\n    print(f\"사용할 장치: {device}\")\n\n    model = DNN().to(device)\n\n    learning_rate = 1e-3\n    batch_size = 64\n    epochs = 10\n\n\n    loss_fn = nn.CrossEntropyLoss().to(device)\n    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n\n    for t in range(epochs):\n        print(f'Epoch {t+1}\\n--------------------------------------')\n        train_loop(train_dataloader, model, loss_fn, optimizer, device)\n        test_loop(train_dataloader, model, loss_fn, device)\n    print(\"Done!\")","metadata":{"execution":{"iopub.status.busy":"2022-11-16T15:21:46.215628Z","iopub.execute_input":"2022-11-16T15:21:46.215970Z","iopub.status.idle":"2022-11-16T15:21:46.223013Z","shell.execute_reply.started":"2022-11-16T15:21:46.215941Z","shell.execute_reply":"2022-11-16T15:21:46.221923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%timeit run('cpu')","metadata":{"execution":{"iopub.status.busy":"2022-11-16T15:21:47.570787Z","iopub.execute_input":"2022-11-16T15:21:47.571994Z","iopub.status.idle":"2022-11-16T15:43:26.976655Z","shell.execute_reply.started":"2022-11-16T15:21:47.571958Z","shell.execute_reply":"2022-11-16T15:43:26.975599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%timeit run('cuda:0')","metadata":{"execution":{"iopub.status.busy":"2022-11-16T15:43:26.978498Z","iopub.execute_input":"2022-11-16T15:43:26.979149Z","iopub.status.idle":"2022-11-16T16:01:08.357294Z","shell.execute_reply.started":"2022-11-16T15:43:26.979108Z","shell.execute_reply":"2022-11-16T16:01:08.355442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}