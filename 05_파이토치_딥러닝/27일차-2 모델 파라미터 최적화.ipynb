{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e387dca-3817-4288-a105-c54f8b1bf96a",
   "metadata": {},
   "source": [
    "# 모델 파라미터 최적화\n",
    "\n",
    "\n",
    "## 라이브러리 임포트 및 패션 MNIST 데이터셋 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "029e48c0-ce84-402c-ab6a-d079a8dfe373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2795563b-e9ec-445a-b3b2-5a38885bcb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트레이닝 데이터셋을 다운로드한다.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "# 테스트 데이터셋을 다운로드한다.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34790cb5-704a-4886-a764-b9625eff71fd",
   "metadata": {},
   "source": [
    "## 모델 구성하기\n",
    "훈련 모델을 작성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8704de-85a0-47ac-a9f7-cf615ad337ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(784, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            #nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    # 포워드 패스    \n",
    "    def forward(self, x):\n",
    "        return self.linear_relu_stack(x)\n",
    "    \n",
    "model = DNN()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee6d0a3-accd-40d3-9ed3-cec1b9858666",
   "metadata": {},
   "source": [
    "## 하이퍼 파라미터, 손실 함수, 옵티마이저 설정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb50fdc-3c62-49f8-bb77-5ef23c9e2bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------------\n",
      "loss: 2.2948665618896484, [    0/60000]\n",
      "loss: 2.2949576377868652, [ 6400/60000]\n",
      "loss: 2.2908880710601807, [12800/60000]\n",
      "loss: 2.2933895587921143, [19200/60000]\n",
      "loss: 2.2907142639160156, [25600/60000]\n",
      "loss: 2.287149667739868, [32000/60000]\n",
      "loss: 2.293658971786499, [38400/60000]\n",
      "loss: 2.289292097091675, [44800/60000]\n",
      "loss: 2.292562484741211, [51200/60000]\n",
      "loss: 2.2885749340057373, [57600/60000]\n",
      "Test Error: \n",
      " 정확도: 27.1% 평균 Loss: 0.000000\n",
      "\n",
      "Epoch 2\n",
      "--------------------------------------\n",
      "loss: 2.2927932739257812, [    0/60000]\n",
      "loss: 2.2928853034973145, [ 6400/60000]\n",
      "loss: 2.2880566120147705, [12800/60000]\n",
      "loss: 2.2912180423736572, [19200/60000]\n",
      "loss: 2.287762403488159, [25600/60000]\n",
      "loss: 2.283536195755005, [32000/60000]\n",
      "loss: 2.2914621829986572, [38400/60000]\n",
      "loss: 2.286160945892334, [44800/60000]\n",
      "loss: 2.290215492248535, [51200/60000]\n",
      "loss: 2.2854504585266113, [57600/60000]\n",
      "Test Error: \n",
      " 정확도: 27.3% 평균 Loss: 0.000000\n",
      "\n",
      "Epoch 3\n",
      "--------------------------------------\n",
      "loss: 2.290411949157715, [    0/60000]\n",
      "loss: 2.2904293537139893, [ 6400/60000]\n",
      "loss: 2.2846975326538086, [12800/60000]\n",
      "loss: 2.288649797439575, [19200/60000]\n",
      "loss: 2.2841532230377197, [25600/60000]\n",
      "loss: 2.27915620803833, [32000/60000]\n",
      "loss: 2.288837432861328, [38400/60000]\n",
      "loss: 2.282350540161133, [44800/60000]\n",
      "loss: 2.2874627113342285, [51200/60000]\n",
      "loss: 2.2816364765167236, [57600/60000]\n",
      "Test Error: \n",
      " 정확도: 27.5% 평균 Loss: 0.000000\n",
      "\n",
      "Epoch 4\n",
      "--------------------------------------\n",
      "loss: 2.287564754486084, [    0/60000]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimzer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train() # 모델을 훈련 모드로 설정\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        pred = model(X) # 포워드 패스 수행\n",
    "        loss = loss_fn(pred, y) # CE 연산\n",
    "        \n",
    "        optimzer.zero_grad() # 0 으로 초기화\n",
    "        loss.backward() # 역전파하여 그래디언트 계산\n",
    "        optimzer.step() # 연산된 그래디언트를 사용해 파라미터를 업데이트\n",
    "        \n",
    "        if batch % 100 == 0: # 매 100회차 마다 다음 내용 출력\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f'loss: {loss}, [{current:>5d}/{size:>5d}]')\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    model.eval() # 모델을 실행 모드로 설정\n",
    "    \n",
    "    with torch.no_grad(): # 그래디언트 연산 안함\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X) # 포워드 패스 수행\n",
    "            test_loss += loss_fn(pred, y) # CE 연산\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item() # 결과 일치하는지 확인\n",
    "    \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f'Test Error: \\n 정확도: {(100*correct):>0.1f}% 평균 Loss: {test_loss:>8f}\\n')\n",
    "    \n",
    "for t in range(epochs):\n",
    "    print(f'Epoch {t+1}\\n--------------------------------------')\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(train_dataloader, model, loss_fn)\n",
    "print(\"Done!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e13f17-acb6-4fc1-89ef-4e45f93780a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77fbc6e-f322-4226-80fb-95e840f5f612",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
