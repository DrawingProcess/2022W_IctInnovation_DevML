{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "466c145c-4b46-4d47-a031-90f4aa30dacd",
   "metadata": {},
   "source": [
    "# 파이토치 빠르게 시작하기\n",
    "\n",
    "## 파이토치 설치와 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "326d500f-e51c-4d04-a5ad-45edb9c4f14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25ecc7e8-a8d5-4fd8-9d13-0dab1e5b2141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc744271-857f-4779-bd2a-aafc7216a239",
   "metadata": {},
   "source": [
    "## 패션 MNIST 데이터셋 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "071e5891-2e05-41ad-a735-5ec305fd2d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트레이닝 데이터셋을 다운로드한다.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "# 테스트 데이터셋을 다운로드한다.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a5590b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a3ddf71e80>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = test_data[0][0].numpy() * 255\n",
    "img = img.astype(np.int32).reshape(28,28)\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "#Z = np.array([[20,5,2],[2,20,3],[11,2,20]])\n",
    "#plt.imshow(Z, cmap = cm.gray)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d89266-fc6e-4fbc-9205-1d69044b01f3",
   "metadata": {},
   "source": [
    "## 배치사이즈를 설정하고 데이터 로더를 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2650ff86-7588-46c4-b225-8510e1d5b437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# 데이터로더 정의\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcd433f-038f-42fa-8455-2b372a26bc5f",
   "metadata": {},
   "source": [
    "## CPU 대신에 GPU를 사용하도록 설정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f546e6-cfdf-4c38-bdac-14075b19d33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else  \"cpu\"\n",
    "\n",
    "# 위 코드는 아래 코드 내용을 한 줄로 표현한 것\n",
    "'''\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "'''\n",
    "\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d77d4f-26ea-4937-bc41-9eaec35cf66c",
   "metadata": {},
   "source": [
    "## 간단한 NN 작성\n",
    "\n",
    "784x512, 512x512, 512x10의 노드를 가진 네트워크를 구성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce8e7031-25d2-4613-9728-7c56b4b41259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NerualNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NerualNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NerualNetwork().to(device) # 변수를 cuda로 보냄\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac4dc8b-4b40-4604-b7c3-98236fd828b3",
   "metadata": {},
   "source": [
    "## 하이퍼파라미터를 구성\n",
    "손실 함수와 최적화 알고리즘을 선택한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2e07ce4-afb6-4906-8a82-8b4de8148e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3) # 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08992f90-284f-4e96-8fe2-8461d8fd4261",
   "metadata": {},
   "source": [
    "## 학습 및 평가 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c377d281-83f7-4af5-b824-b534351fca18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------------\n",
      "loss: 2.304574 [    0/60000]\n",
      "loss: 2.288394 [ 6400/60000]\n",
      "loss: 2.272907 [12800/60000]\n",
      "loss: 2.262149 [19200/60000]\n",
      "loss: 2.263522 [25600/60000]\n",
      "loss: 2.228719 [32000/60000]\n",
      "loss: 2.233218 [38400/60000]\n",
      "loss: 2.204882 [44800/60000]\n",
      "loss: 2.195437 [51200/60000]\n",
      "loss: 2.165795 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 42.9%, Avg loss: 2.163326\n",
      "\n",
      "Epoch 2\n",
      "--------------------------------------\n",
      "loss: 2.180132 [    0/60000]\n",
      "loss: 2.171099 [ 6400/60000]\n",
      "loss: 2.116764 [12800/60000]\n",
      "loss: 2.126272 [19200/60000]\n",
      "loss: 2.100520 [25600/60000]\n",
      "loss: 2.029132 [32000/60000]\n",
      "loss: 2.058379 [38400/60000]\n",
      "loss: 1.986299 [44800/60000]\n",
      "loss: 1.983852 [51200/60000]\n",
      "loss: 1.916324 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 1.917415\n",
      "\n",
      "Epoch 3\n",
      "--------------------------------------\n",
      "loss: 1.964308 [    0/60000]\n",
      "loss: 1.934472 [ 6400/60000]\n",
      "loss: 1.819469 [12800/60000]\n",
      "loss: 1.841753 [19200/60000]\n",
      "loss: 1.764568 [25600/60000]\n",
      "loss: 1.697927 [32000/60000]\n",
      "loss: 1.718900 [38400/60000]\n",
      "loss: 1.615675 [44800/60000]\n",
      "loss: 1.633573 [51200/60000]\n",
      "loss: 1.528595 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 1.545191\n",
      "\n",
      "Epoch 4\n",
      "--------------------------------------\n",
      "loss: 1.632890 [    0/60000]\n",
      "loss: 1.586726 [ 6400/60000]\n",
      "loss: 1.431544 [12800/60000]\n",
      "loss: 1.488372 [19200/60000]\n"
     ]
    }
   ],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train() # 모델이 학습하도록 트레인 단계를 활성화\n",
    "    \n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # 모델의 에러를 계산\n",
    "        pred = model(X) # 포워드 연산\n",
    "        loss = loss_fn(pred, y) # loss 연산\n",
    "        \n",
    "        # 역전파\n",
    "        optimizer.zero_grad() # 매 이터레이션마다 그래디언트를 초기화\n",
    "        loss.backward() # 역전파가 진행되어 w,r,t 그래프잎의 기울기를 계산한다.\n",
    "        optimizer.step() # 가중치 업데이트\n",
    "        \n",
    "        if batch % 100 == 0: # 매 100회 배치를 돌 때마다 리포트 수행\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval() # 평가를 수행한다는 의미\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad(): # 그라데이션 계산을 비활성화\n",
    "        for X,y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # 모델의 에러를 계산\n",
    "            pred = model(X) # 포워드 연산\n",
    "            test_loss += loss_fn(pred, y).item() # loss 연산\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\\n\")\n",
    "\n",
    "    \n",
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f'Epoch {t+1}\\n--------------------------------------')\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5681066f-d562-42a0-99af-e5d63366b996",
   "metadata": {},
   "source": [
    "## 모델 저장과 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6b9897-4069-4656-acf3-71f8e3d33996",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Pytorch 모델의 상태를 model.pth에 저장했다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d315e7-1089-44e0-957f-4b4e7b54e7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = NerualNetwork()\n",
    "model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6099647-b49d-4bb4-842e-95e73b72d719",
   "metadata": {},
   "source": [
    "## 불러온 모델을 사용해 예측 수행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8ea473-eed8-4ecf-9040-df5c37f754c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouse\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c49db8-37f1-400b-a617-4b8df165e4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "img = test_data[0][0].numpy() * 255\n",
    "img = img.astype(np.int32).reshape(28,28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7689e1e-3c89-433a-b699-dfd910eec651",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cce0b61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
