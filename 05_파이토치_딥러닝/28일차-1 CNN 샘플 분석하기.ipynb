{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d1ec6fe-8f16-411e-a331-da0993827c3c",
   "metadata": {},
   "source": [
    "# CNN 샘플 분석하기\n",
    "## CNN 샘플에 필요한 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f353d14b-17f0-4d20-94c0-31a9048bb7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.init\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc545e2-f1cf-4f44-8e17-255bb7eccb48",
   "metadata": {},
   "source": [
    "## 랜덤 시드 고정 및 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b87ef450-1bcf-4819-8a91-d94202140d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f030948d5274d469fe00f8cd9c70efe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\train-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef90c58ca964429db3584a4422d9da11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\train-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4acca061174e4ab1ab38392c27dfef5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29e4d087748f405ebb63a393288dc3b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 랜덤 시드 고정\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# GPU 사용 가능일 경우 랜덤 시드 고정\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "\n",
    "# 데이터셋 가져오기\n",
    "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
    "                          train=True, \n",
    "                          transform=transforms.ToTensor(), \n",
    "                          download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
    "                         train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19be03c5-8c6f-495e-b0cf-8d7b2759ebaa",
   "metadata": {},
   "source": [
    "## 하이퍼 파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15e18699-e456-4218-bab6-37c30837d507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼 파라미터 설정\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# 데이터 로더 정의\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6e48ad6-6492-4ec5-95bb-65ad40fb8ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAdam은 GradientDescentOptimizer에 비해 몇 가지 장점을 제공\\nmoving averages of the parameters를 사용(momentum) \\nAdam은 더 큰 효과적인 step size를 사용할 수 있으며 알고리즘은 튜닝 없이 이 단계 크기로 수렴\\nAdam이 각 트레이닝 단계에서 각 매개 변수에 대해 더 많은 계산을 수행 \\n(이동 평균 및 분산을 유지하고 크기 조정 된 그라디언트를 계산하기 위해)\\n각 매개 변수에 대해 더 많은 상태를 유지 \\n(각 매개 변수의 평균 및 분산을 저장하기 위해 모델의 크기를 약 3 배로 늘림)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNN 모델 정의\n",
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # 첫번째층\n",
    "        # ImgIn shape=(?, 28, 28, 1)\n",
    "        #    Conv     -> (?, 28, 28, 32)\n",
    "        #    Pool     -> (?, 14, 14, 32)\n",
    "        \n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            # 1채널의 이미지를 인풋으로 받는다.\n",
    "            # 커널의 개수는 32개이며 사이즈는 3x3이다. \n",
    "            # 이미지를 계산할 때는 한 칸씩이동하여 계산하며\n",
    "            # 패딩 값이 있으므로 이미지 사이즈가 줄지 않는다.\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            # 0이하의 값은 0이되며 0보다 큰 값만 살아 남는다.\n",
    "            torch.nn.ReLU(),\n",
    "            # 2x2마다 최대 값을 추출한다.\n",
    "            # 이미지의 사이즈가 절반으로 줄어든다.\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        # 두번째층\n",
    "        # ImgIn shape=(?, 14, 14, 32)\n",
    "        #    Conv      ->(?, 14, 14, 64)\n",
    "        #    Pool      ->(?, 7, 7, 64)\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        # 전결합층 7x7x64 inputs -> 10 outputs\n",
    "        self.fc = torch.nn.Linear(7 * 7 * 64, 10, bias=True)\n",
    "\n",
    "        # 전결합층 한정으로 가중치 초기화\n",
    "        # Sigmoid와 같은 S자 함수의 경우, 가장 중요한 것은 출력값들이 표준 정규 분포 형태를 갖게 하는 것\n",
    "        # Xavier(사비에르) Initialization 방법은, 단순히 가중치를 작은 값의 표준편차를 갖는 형태로 초기화 하는 것이 아닌, 보다 발전된 방법\n",
    "        # 출처: https://wooono.tistory.com/223\n",
    "        torch.nn.init.xavier_uniform_(self.fc.weight)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 포워드 패스\n",
    "        out = self.layer1(x)   # conv layer\n",
    "        out = self.layer2(out) # conv layer\n",
    "        out = out.view(out.size(0), -1)   # 전결합층을 위해서 Flatten\n",
    "        out = self.fc(out) # full connected layer\n",
    "        return out\n",
    "\n",
    "    \n",
    "# CNN 모델 생성\n",
    "model = CNN().to(device)\n",
    "\n",
    "# 로스와 최적화 함수 설정\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "'''\n",
    "Adam은 GradientDescentOptimizer에 비해 몇 가지 장점을 제공\n",
    "moving averages of the parameters를 사용(momentum) \n",
    "Adam은 더 큰 효과적인 step size를 사용할 수 있으며 알고리즘은 튜닝 없이 이 단계 크기로 수렴\n",
    "Adam이 각 트레이닝 단계에서 각 매개 변수에 대해 더 많은 계산을 수행 \n",
    "(이동 평균 및 분산을 유지하고 크기 조정 된 그라디언트를 계산하기 위해)\n",
    "각 매개 변수에 대해 더 많은 상태를 유지 \n",
    "(각 매개 변수의 평균 및 분산을 저장하기 위해 모델의 크기를 약 3 배로 늘림)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "063b81f4-f82a-4e40-acc5-50d864e39c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 배치의 수 : 600\n",
      "[Epoch:    1] cost = 0.215979591\n",
      "[Epoch:    2] cost = 0.0623616278\n",
      "[Epoch:    3] cost = 0.0443787314\n",
      "[Epoch:    4] cost = 0.0355432183\n",
      "[Epoch:    5] cost = 0.0289978608\n",
      "[Epoch:    6] cost = 0.0254101083\n",
      "[Epoch:    7] cost = 0.0199933145\n",
      "[Epoch:    8] cost = 0.0177171528\n",
      "[Epoch:    9] cost = 0.0151013359\n",
      "[Epoch:   10] cost = 0.0122582028\n",
      "[Epoch:   11] cost = 0.0104048718\n",
      "[Epoch:   12] cost = 0.00806191936\n",
      "[Epoch:   13] cost = 0.00765087875\n",
      "[Epoch:   14] cost = 0.00629990129\n",
      "[Epoch:   15] cost = 0.00545077305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isc03\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:80: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "C:\\Users\\isc03\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:70: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.988099992275238\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 데이터 로드\n",
    "total_batch = len(data_loader)\n",
    "print('총 배치의 수 : {}'.format(total_batch))\n",
    "\n",
    "# 트레이닝 데이터셋으로 epoch 실행\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for X, Y in data_loader: # 미니 배치 단위로 꺼내온다. X는 미니 배치, Y는 레이블.\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad() # 기울기 초기화\n",
    "        hypothesis = model(X) # 모델 연산 후 결과 저장\n",
    "        cost = criterion(hypothesis, Y) # 오류 산출\n",
    "        cost.backward()  # 역전파 수행\n",
    "        optimizer.step() # 업데이트 수행\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))\n",
    "\n",
    "    \n",
    "# 학습을 진행하지 않을 것이므로 torch.no_grad()\n",
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b3525e-a671-4da8-8ada-5de8bdf676d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
